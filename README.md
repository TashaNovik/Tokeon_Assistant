# Инструкция

Для тестового запуска: запустить докер, выполнить:
docker run -p 6333:6333 -p 6334:6334     -v "$(pwd)/qdrant_storage:/qdrant/storage:z"     qdrant/qdrant
Запустить программу.

При первом запуске обязательно base_directory="knowledge_base" - на 6333 Qdrant
это адрес папки в директории программы, в которой лежит вся база знаний от Дмитрия - туда нужно ее сохранить
Программа обходит все папки и создает коллекции с векторными представлениями в БД по названию файла: 1 файл = 1 коллекция.
Это может занять 15+ минут.
http://localhost:6333/dashboard#/collections/ - здесь можно увидеть все коллекции, созданные в Qdrant

Далее на основании базы знаний создается JSON (это временное неоптимальное решение) в папке 
/context/context.json - в нем содержатся токены слов по базе знаний:
предложения токенизированы, выкинуты стоп-слова с помощью nltk.
При первом запуске создается папка nltk и скачиваются stopwords

На основе токенизированного контекста обучается небольшая модель синонимов - FastText
Она сохраняется в папке fasttext в текущей директории
На этом этапе работа с базой знаний закончена (33 строка).
При изменении файла в базе знаний нужно просто направить директорию папки, где обновился файл или ссылку на этот файл: base_directory=...
____________________________________________________________

Далее работа с вопросом: он токенизируется, лемматизируется, к каждому токену добавляется топ2 слова из синонимов FastText
После этого доработаный вопрос отправляется на векторизацию и ищутся лучшие совпадения чанков - для GPT топ5 Large чанков по совпадениям Small.
(поиск совпадений по малым чанкам, они привязаны к большому. Большой чанк для сохранения смысла текста -~2500 символов)

Лучший топ совпадений идет в GPT c системным промптом.
____________________________________________________________
Работа с YaGPT:
Инструкция для подключения: https://yandex.cloud/ru/docs/iam/operations/iam-token/create#exchange-token

В данном случае автосозданная дефолтная
один запрос в яндекс lite стоит примерно 20 копеек
