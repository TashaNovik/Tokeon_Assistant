from asyncio import to_thread
from tokeon_assistant_rest_api.clients.api import get_token, send_request_to_yagpt
from tokeon_assistant_rest_api.clients.knowledge_base_client import KnowledgeBaseClient
import json
from tokeon_assistant_rest_api.config import settings
import logging

logger = logging.getLogger(__name__)

# Initialize the Knowledge Base client
kb_client = KnowledgeBaseClient()

async def answer_from_knowledge_base(raw_question: str) -> str:
    """
    Processes a user's raw question to generate an answer using the knowledge base and an AI model.

    The function performs the following steps asynchronously:
    1. Logs the raw question.
    2. Lemmatizes the question text using a Russian lemmatizer.
    3. Extracts the main question from lemmas.
    4. Prepares relevant knowledge base data for the question.
    5. Obtains an authentication token for the AI model.
    6. Sends a request to the AI model with the user prompt and system instructions.
    7. Logs and returns the generated answer.

    Args:
        raw_question (str): The original user question.

    Returns:
        str: The answer generated by the AI model based on the knowledge base.
    """
    logger.info(f"Question: {raw_question}")
    kb_data_for_question = await kb_client.prepare_question(raw_question)
    logger.info(f"KB data for question: {kb_data_for_question[:100]}")
    iam = await to_thread(get_token, settings.ya_gpt.api_key)

    answer = await to_thread(
        send_request_to_yagpt,
        iam,
        getUserPrompt(raw_question, kb_data_for_question),
        system_prompt=getSystemPrompt(),
        temperature=0.0,
    )
    logger.info(f"Answer: {answer}")
    return answer

def getSystemPrompt() -> str:
    """
    Returns the system prompt string for the AI assistant.

    This prompt defines the assistant's role, rules, and constraints,
    instructing it to provide answers strictly based on the given knowledge base chunks.

    Returns:
        str: The system prompt text in Russian.
    """
    return """Ты — ИИ-ассистент службы поддержки компании "Токеон".
Твоя основная задача — предоставлять точные и полезные ответы на вопросы пользователей, касающиеся продуктов, услуг и процедур компании "Токеон".
Твои ответы должны основываться **ИСКЛЮЧИТЕЛЬНО** на информации, предоставленной в поле "knowledge_base_chunks" JSON-структуры в сообщении пользователя.
Вопрос пользователя находится в поле "user_question" этой же JSON-структуры.

**Строгие правила твоего поведения:**

1.  **Источник информации:** Внимательно изучи содержимое каждого элемента в массиве "knowledge_base_chunks". Каждый элемент представляет собой фрагмент из базы знаний компании "Токеон" и содержит поля "source" (источник фрагмента) и "text_content" (текст фрагмента). Используй **только** "text_content" из этих фрагментов для формирования ответов. Категорически запрещается использовать любые твои общие знания, предположения или информацию из других источников.
2.  **Полнота ответа:** Старайся давать максимально полный и подробный ответ на "user_question" на основе предоставленного "text_content". Если в контексте есть шаги, реквизиты, ссылки или важные детали, обязательно включай их в ответ, как в примере: "Как пополнить счет... 1. Зайдите... 2. Переведите...".
3.  **Если информация отсутствует:** Если в "knowledge_base_chunks" (даже если массив пуст) нет достаточной информации для ответа на "user_question", ты должен четко и вежливо сообщить об этом. Используй одну из следующих фраз:
    *   "К сожалению, я не смог(ла) найти точный ответ на ваш вопрос в базе знаний компании Токеон."
    *   "На данный момент у меня нет информации по вашему запросу в базе знаний. Я передам ваш вопрос специалистам для уточнения."
    *   "Информация по вашему вопросу отсутствует в моей базе знаний. Пожалуйста, попробуйте переформулировать вопрос или обратитесь к другим ресурсам компании."
    Не пытайся угадывать или придумывать ответ.
4.  **Непонятный вопрос:** Если "user_question" неясен, слишком общий или его невозможно соотнести с предоставленным контекстом, вежливо попроси пользователя уточнить свой запрос. Например: "Не могли бы вы, пожалуйста, уточнить ваш вопрос, чтобы я мог(ла) предоставить наиболее релевантную информацию из базы знаний Токеон?"
5.  **Стиль общения:** Будь вежлив, профессионален и дружелюбен. Твоя цель — помочь пользователю.
6.  **Персональные данные:** Не запрашивай и не пытайся собрать никакие персональные данные у пользователя (ФИО, телефон, email, номер договора и т.д.).

Твоя работа очень важна для компании "Токеон" и ее клиентов. Стремись предоставлять качественную поддержку.
"""

def getUserPrompt(raw_question: str, prepared_kb_chunks: list) -> str:
    """
    Constructs a JSON-formatted user prompt combining the raw question and knowledge base chunks.

    Args:
        raw_question (str): The original user question.
        prepared_kb_chunks (list): The prepared knowledge base data relevant to the question.

    Returns:
        str: A JSON string with fields "user_question" and "knowledge_base_chunks" to be sent to the AI model.
    """
    prompt_data = {
        "user_question": raw_question,
        "knowledge_base_chunks": f"{prepared_kb_chunks}",
    }

    # ensure_ascii=False to correctly handle Cyrillic characters
    # indent=2 for readability during debugging, can be removed for production to save tokens
    user_prompt_json = json.dumps(prompt_data, ensure_ascii=False, indent=2)

    logger.info(f"User prompt JSON: {user_prompt_json}")
    return user_prompt_json